# local-llm

Run LLMs locally using ollama.
Download ollama in Mac, add it as a command.
Run command "Ollama pull llama2"
Run llama2

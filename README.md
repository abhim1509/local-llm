# local-llm

Run LLMs locally using ollama without internet!
Download ollama in Mac, add it as a command.
Run command "Ollama pull llama2"
Run llama2
